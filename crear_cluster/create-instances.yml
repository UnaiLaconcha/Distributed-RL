---
# ------------------------------
#       LOCALHOST
# -------------------------------

- hosts: localhost
  # Se cargan las variables que se toman del script de bash para parametrizar la
  # creacion de las instancias
  vars:
    master_instance_type: "{{ master_instance_type | default('t3.large') }}"
    worker_instance_type: "{{ worker_instance_type | default('t3.large') }}"
    client_instance_type: "{{ client_instance_type | default('t3.large') }}"
    num_workers: "{{ num_workers | default(4) }}"
  
  tasks:

  # Obtiene la dirección IP pública de la máquina local
  - name: Get my public IP
    community.general.ipify_facts:

  # Crea un grupo de seguridad para la comunicación interna del clúster
  - name: Create security group for node communication
    amazon.aws.ec2_security_group:
      name: hadoop-sg
      description: sg with total access within hadoop nodes
      region: us-east-1
      rules:
        - proto: all
          group_name: hadoop-sg
        - proto: tcp
          cidr_ip: "{{ ipify_public_ip }}/32"
          ports: 
          - 22

  # Crea un grupo de seguridad para el acceso externo al nodo maestro
  - name: Create a security group for master communication to outside
    amazon.aws.ec2_security_group:
      name: hadoop-master-sg
      description: sg with partial access to hadoop-master node
      region: us-east-1
      rules:
        - proto: tcp
          group_name: hadoop-master-sg
          ports:
          - 22
          - 7077
        - proto: tcp
          cidr_ip: "{{ ipify_public_ip }}/32"
          ports: 
          - 22

  # Crea un grupo de seguridad para el acceso al nodo cliente
  - name: Create a security group for client communication to outside
    amazon.aws.ec2_security_group:
      name: hadoop-client-sg
      description: sg with partial access to hadoop-master node
      region: us-east-1
      rules:
        - proto: all
          group_name: hadoop-client-sg
        - proto: tcp
          cidr_ip: "{{ ipify_public_ip }}/32"
          ports: 
          - 22
          - 8888

  # Lanza la instancia del nodo maestro de Hadoop
  - name: Start hadoop master instance
    amazon.aws.ec2_instance:
      name: "hadoop-master"
      key_name: "vockey"
      instance_type: "{{ master_instance_type }}"
      security_groups: 
        - hadoop-sg
        - hadoop-master-sg
      image_id: ami-066784287e358dad1
      region: us-east-1
      state: running
      tags:
        Group: hadoop-master
      volumes:
      - device_name: /dev/xvda
        ebs:
          volume_size: 50
          delete_on_termination: true
    register: hadoop_master_values

  # Lanza la instancia del cliente de Hadoop 
  - name: Start client instance
    amazon.aws.ec2_instance:
      name: "client"
      key_name: "vockey"
      instance_type: "{{ client_instance_type }}"
      security_groups: 
        - hadoop-master-sg
        - hadoop-client-sg
      image_id: ami-066784287e358dad1
      region: us-east-1
      state: running
      tags:
        Group: client
      volumes:
      - device_name: /dev/xvda
        ebs:
          volume_size: 50
          delete_on_termination: true
    register: hadoop_client_values
      
  # Lanza las instancias de los nodos trabajadores de Hadoop
  # Se crea un ciclo con la variable de cantidad de workers para 
  # crear un cluster dinámico
  - name: Start hadoop worker instances
    amazon.aws.ec2_instance:
      name: "hadoop-worker-{{item}}"
      key_name: "vockey"
      instance_type: "{{ worker_instance_type }}"
      security_group: hadoop-sg
      image_id: ami-066784287e358dad1
      region: us-east-1
      state: running
      tags:
        Group: hadoop-worker
      volumes:
      - device_name: /dev/xvda
        ebs:
          volume_size: 50
          delete_on_termination: true
    loop: "{{ range(1, num_workers|int + 1)|list }}"
    register: hadoop_worker_values

  # Actualiza el inventario de Ansible
  - meta: refresh_inventory

  # Crea el archivo hosts a partir de la plantilla
  - name: Copy hosts.template to hosts file
    copy: 
      src: hosts.template
      dest: hosts

  # Actualiza la IP del maestro en el archivo hosts
  - name: Replace master host IP in hosts file
    replace:
      path: hosts
      regexp: 'master-node-ip'
      replace: "{{ hadoop_master_values.instances[0].private_ip_address }}"
  
  # Depuración: Muestra las IPs de los trabajadores
  - name: Debug hadoop_worker_values
    debug:
      msg: "{{ item.instances[0].private_ip_address }}"
    loop: "{{ hadoop_worker_values.results }}"

  # Actualiza las IPs de los trabajadores en el archivo hosts 
  # Se recorren todos los workers en el archivo y se les agrega una ip.
  # El regex siempre coincide porque la plantilla se construye desde el bash
  - name: Replace workers host IP in hosts file
    replace:
      path: hosts
      regexp: 'worker-{{ index }}-ip'
      replace: "{{ item.instances[0].private_ip_address }}"
    loop: "{{ hadoop_worker_values.results }}"
    loop_control:
        index_var: index
      
# -------------------------------
#       ALL
# -------------------------------

- hosts: all
  tasks:
  # Copia el archivo hosts a todas las instancias
  - name: Copy hosts file to all hosts
    become: true
    copy:
      src: hosts
      dest: /etc/hosts

  # Copia el archivo de librerías de Python
  - name: Copy requirements for python enviroment
    become: true
    copy:
      src: requirements_rllib.txt
      dest: /home/ec2-user/requirements_rllib.txt

  # Descarga Hadoop en todas las instancias
  - name: Download Hadoop
    ansible.builtin.get_url:
      url: https://dlcdn.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz
      dest: /home/ec2-user
      timeout: 60

  # Extrae el archivo de Hadoop
  - name: Extract Hadoop
    ansible.builtin.command: tar -xf /home/ec2-user/hadoop-3.3.6.tar.gz

  # Instala Java
  - name: Install Java
    ansible.builtin.command: sudo yum install -y java-1.8.0-amazon-corretto java-1.8.0-amazon-corretto-devel

  # Instala Git
  - name: Install git
    ansible.builtin.command: sudo yum install -y git-all

  # Configura la variable de entorno JAVA_HOME
  - name: Set JAVA_HOME environment variable at ~/.bashrc
    ansible.builtin.shell: echo 'export JAVA_HOME=/usr/lib/jvm/java' >> ~/.bashrc

  # Configura la variable de entorno HADOOP_HOME
  - name: Set HADOOP_HOME environment variable at ~/.bashrc
    ansible.builtin.shell: echo 'export HADOOP_HOME=/home/ec2-user/hadoop-3.3.6' >> ~/.bashrc

  # Añade el directorio bin de Hadoop al PATH
  - name: Set Hadoop bin directory to the PATH.
    ansible.builtin.shell: echo 'export PATH=/home/ec2-user/hadoop-3.3.6/bin:$PATH' >> ~/.bashrc

  # Copia el archivo de configuración core-site.xml
  - name: Copy core-site.xml file to all hosts
    ansible.builtin.copy:
      src: core-site.xml
      dest: /home/ec2-user/hadoop-3.3.6/etc/hadoop/core-site.xml

  # Descarga Spark
  - name: Download Spark
    ansible.builtin.get_url:
      url: https://dlcdn.apache.org/spark/spark-3.5.3/spark-3.5.3-bin-hadoop3.tgz
      dest: /home/ec2-user
      timeout: 60

  # Extrae el archivo de Spark
  - name: Extract Spark
    ansible.builtin.command: tar -xf /home/ec2-user/spark-3.5.3-bin-hadoop3.tgz

  # Configura la variable de entorno SPARK_HOME --nv
  - name: Set SPARK_HOME environment variable at ~/.bashrc
    ansible.builtin.shell: echo 'export SPARK_HOME=/home/ec2-user/spark-3.5.3-bin-hadoop3' >> ~/.bashrc

  # Configura la variable de entorno HADOOP_CONF_DIR --nv
  - name: Set HADOOP_CONF_DIR environment variable at ~/.bashrc
    ansible.builtin.shell: echo 'export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop' >> ~/.bashrc

  # Actualiza el CLASSPATH --nv
  - name: Set SPARK_HOME environment variable at ~/.bashrc
    ansible.builtin.shell: echo 'export CLASSPATH=$(hadoop classpath):$CLASSPATH' >> ~/.bashrc

  # Añade el directorio bin de Spark al PATH 
  - name: Set Spark bin directory to the PATH.
    ansible.builtin.shell: echo 'export PATH=/home/ec2-user/spark-3.5.3-bin-hadoop3/bin:$PATH' >> ~/.bashrc  

  # Instala herramienta para instalar paquetes especificos en la instancia de AWS
  - name: Install packages for aws 
    ansible.builtin.shell: sudo yum groupinstall "Development Tools" -y

  # Actualiza las bibliotecas apt para Python 3.10
  - name: Update apt libraries 
    ansible.builtin.shell: sudo yum install gcc openssl-devel bzip2-devel libffi-devel zlib-devel wget tar zip -y 

  # Descarga Python 3.10
  - name: Download Python 3.10
    ansible.builtin.get_url:
      url: https://www.python.org/ftp/python/3.10.13/Python-3.10.13.tgz
      dest: /home/ec2-user/
      timeout: 60

  # Extrae los paquetes de Python
  - name: Extract packages
    ansible.builtin.command: tar -xf /home/ec2-user/Python-3.10.13.tgz

  # Configura Python
  - name: Configure Python
    ansible.builtin.command: 
      cmd: "sudo ./configure --enable-optimizations"
      chdir: "/home/ec2-user/Python-3.10.13"

  # Compila e instala Python
  - name: Compile and install Python
    ansible.builtin.command: 
      cmd: sudo make altinstall
      chdir: "/home/ec2-user/Python-3.10.13"

  # Configura pip
  - name: Configure pip
    ansible.builtin.command: python3.10 -m ensurepip --upgrade

  # Actualiza pip
  - name: Update pip
    ansible.builtin.command: python3.10 -m pip install --upgrade pip

  # Agrega un alias para Python 3.10 y reemplazar el python3 existente
  - name: Add Python alias to bashrc
    ansible.builtin.shell: echo 'alias python3="python3.10"' >> ~/.bashrc

  # Configura Python para PySpark
  - name: Add Python to Spark configuration
    ansible.builtin.shell: echo 'export PYSPARK_PYTHON=/home/ec2-user/Python-3.10.13/python' >> ~/.bashrc

  # Configura el driver de Python para PySpark
  - name: Add Python libraries to Spark configuration
    ansible.builtin.shell: echo 'export PYSPARK_DRIVER_PYTHON=/home/ec2-user/Python-3.10.13/python' >> ~/.bashrc

  # Instala las dependencias para ejecutar los entornos de rllib
  - name: Install dependencies
    ansible.builtin.shell: pip install -r /home/ec2-user/requirements_rllib.txt

# ------------------------------
#       MASTER
# -------------------------------

- hosts: tag_Group_hadoop_master
  tasks:
  # Copia el archivo hdfs-site.xml al nodo maestro de Hadoop
  - name: Copy HDFS site configuration to hadoop-master
    ansible.builtin.copy:
      src: hadoop-master/hdfs-site.xml
      dest: /home/ec2-user/hadoop-3.3.6/etc/hadoop/hdfs-site.xml

  # Copia el archivo yarn-site.xml al nodo maestro de Hadoop
  - name: Copy YARN site configuration to hadoop-master
    ansible.builtin.copy:
      src: hadoop-master/yarn-site.xml
      dest: /home/ec2-user/hadoop-3.3.6/etc/hadoop/yarn-site.xml

  # Copia el archivo de trabajadores al nodo maestro de Hadoop
  - name: Copy workers file to hadoop-master
    ansible.builtin.copy:
      src: hadoop-master/workers
      dest: /home/ec2-user/hadoop-3.3.6/etc/hadoop/workers

  # Crea la ruta de metadatos para el NameNode
  - name: Create NameNode metadata directory
    ansible.builtin.file:
      path: /home/ec2-user/nn
      state: directory

  # Formatea el directorio del NameNode
  - name: Format NameNode directory
    ansible.builtin.shell: /home/ec2-user/hadoop-3.3.6/bin/hdfs namenode -format -force

  # Copia el archivo de servicio del NameNode al nodo maestro de Hadoop
  - name: Copy NameNode service file to hadoop-master
    become: true
    ansible.builtin.copy:
      src: hadoop-master/namenode.service
      dest: /etc/systemd/system/namenode.service

  # Inicia el servicio del NameNode
  - name: Start NameNode service
    become: true
    ansible.builtin.shell: systemctl start namenode

  # Configura el servicio del NameNode para que se inicie al arrancar el sistema
  - name: Enable NameNode service on boot
    become: true
    ansible.builtin.shell: systemctl enable namenode

  # Copia el archivo yarn-site.xml al nodo maestro de Hadoop
  - name: Copy YARN site configuration to hadoop-master node
    ansible.builtin.copy:
      src: hadoop-master/yarn-site.xml
      dest: /home/ec2-user/hadoop-3.3.6/etc/hadoop/yarn-site.xml

  # Copia el archivo mapred-site.xml al nodo maestro de Hadoop
  - name: Copy MapReduce site configuration to hadoop-master node
    ansible.builtin.copy:
      src: hadoop-master/mapred-site.xml
      dest: /home/ec2-user/hadoop-3.3.6/etc/hadoop/mapred-site.xml

  # Configura la variable de entorno HADOOP_CLASSPATH
  - name: Set HADOOP_CLASSPATH environment variable
    ansible.builtin.shell: echo 'export HADOOP_CLASSPATH=$JAVA_HOME/lib/tools.jar' >> ~/.bashrc

  # Copia el archivo de servicio de Spark al nodo maestro de Hadoop --nv
  - name: Copy Spark master service file to hadoop-master
    become: true
    ansible.builtin.copy:
      src: hadoop-master/sparkmaster.service
      dest: /etc/systemd/system/sparkmaster.service

  # Copia el archivo hdfs-site.xml al directorio de configuración de Spark
  - name: Copy HDFS site configuration to Spark directory
    ansible.builtin.copy:
      src: hadoop-master/hdfs-site.xml
      dest: /home/ec2-user/spark-3.5.3-bin-hadoop3/conf/hdfs-site.xml

  # Inicia el servicio de Spark master
  - name: Start Spark master service
    become: true
    systemd:
      state: started
      name: sparkmaster
      daemon_reload: true
      enabled: true

# ------------------------------
#       CLIENT
# -------------------------------

- hosts: tag_Group_client
  tasks:
  - name: Update pip for python 3.9
    ansible.builtin.shell: python3.9 -m ensurepip --upgrade

  # Copia el archivo hdfs-site.xml al nodo maestro de Hadoop
  - name: Install jupyterlab to run queries
    ansible.builtin.shell: pip3.9 install jupyterlab


# -------------------------------
#           WORKERS
# -------------------------------

- hosts: tag_Group_hadoop_worker

  tasks:

  # Copia el archivo spark-env.sh a todos los nodos trabajadores que contiene las dimensiones de Hardwire
  # de los workers
  - name: Copy Spark environment configuration to worker nodes
    become: true
    copy:
      src: hadoop-master/spark-env.sh
      dest: /home/ec2-user/spark-3.5.3-bin-hadoop3/conf/spark-env.sh

  # Configurar HDFS

  # Copia el archivo hdfs-site.xml a los nodos trabajadores de Hadoop
  - name: Copy HDFS site configuration to Hadoop worker nodes
    ansible.builtin.copy:
      src: hadoop-worker/hdfs-site.xml
      dest: /home/ec2-user/hadoop-3.3.6/etc/hadoop/hdfs-site.xml

  # Copia el archivo hdfs-site.xml al directorio de configuración de Spark en los nodos trabajadores
  - name: Copy HDFS site configuration to Spark directory on worker nodes
    ansible.builtin.copy:
      src: hadoop-worker/hdfs-site.xml
      dest: /home/ec2-user/spark-3.5.3-bin-hadoop3/conf/hdfs-site.xml

  # Crea el directorio para el DataNode
  - name: Create DataNode directory
    ansible.builtin.file:
      path: /home/ec2-user/dn
      state: directory

  # Copia el archivo de servicio del DataNode a los nodos trabajadores
  - name: Copy DataNode service file to worker nodes
    become: true
    ansible.builtin.copy:
      src: hadoop-worker/datanode.service
      dest: /etc/systemd/system/datanode.service

  # Inicia el servicio del DataNode
  - name: Start DataNode service
    become: true
    ansible.builtin.shell: systemctl start datanode

  # Configura el servicio del DataNode para que se inicie al arrancar el sistema
  - name: Enable DataNode service on boot
    become: true
    ansible.builtin.shell: systemctl enable datanode

  # Copia el archivo yarn-site.xml a los nodos trabajadores
  - name: Copy YARN site configuration to worker nodes
    ansible.builtin.copy:
      src: hadoop-worker/yarn-site.xml
      dest: /home/ec2-user/hadoop-3.3.6/etc/hadoop/yarn-site.xml

  # INICIA SPARK

  # Añade la URL del maestro de Spark al archivo .bashrc en los nodos trabajadores
  - name: Add Spark master URL to .bashrc in worker nodes
    lineinfile:
      path: /home/ec2-user/.bashrc
      line: "export SPARK_MASTER_URL=spark://hadoop-master:7077"
      state: present

  # Copia el archivo de servicio del trabajador de Spark a los nodos trabajadores
  - name: Copy Spark worker service file to worker nodes
    become: true
    ansible.builtin.copy:
      src: hadoop-worker/sparkworker.service
      dest: /etc/systemd/system/sparkworker.service

  # Inicia el servicio del trabajador de Spark
  - name: Start Spark worker service
    become: true
    systemd:
      state: started
      name: sparkworker
      daemon_reload: true
      enabled: true

  # INICIA YARN

  # # Copia el archivo de servicio del NodeManager a los nodos trabajadores
  # - name: Copy NodeManager service file to worker nodes
  #   become: true
  #   ansible.builtin.copy:
  #     src: hadoop-worker/nodemanager.service
  #     dest: /etc/systemd/system/nodemanager.service

  # # Inicia el servicio del NodeManager
  # - name: Start NodeManager service
  #   become: true
  #   systemd:
  #     state: started
  #     name: nodemanager
  #     daemon_reload: true
  #     enabled: true

# REMOVER PERMISOS DE SSH 

- hosts: localhost
  tasks:
  # Actualiza el grupo de seguridad para eliminar el acceso SSH a los trabajadores
  - name: Update security group to remove SSH access to workers
    amazon.aws.ec2_security_group:
      name: hadoop-sg
      description: Security group with total access within Hadoop nodes
      region: us-east-1
      rules:
        - proto: all
          group_name: hadoop-sg

  # Asocia una nueva IP elástica con la instancia maestra 
  # - name: Associate new elastic IP with the master instance
  #   amazon.aws.ec2_eip:
  #     device_id: "{{ item }}"
  #     region: us-east-1
  #   loop: "{{ hadoop_master_values.instance_ids }}"